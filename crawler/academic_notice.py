import requests
import pymysql
import hashlib
from bs4 import BeautifulSoup
import urllib3
import datetime
import os
from dotenv import load_dotenv

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# .env ë¡œë“œ
load_dotenv()

def clean_date(date_str):
    try:
        dt = datetime.datetime.strptime(date_str.strip(), "%Y.%m.%d")
        return dt.strftime("%Y-%m-%d")
    except ValueError:
        return date_str.strip()

def generate_hash(title, link):
    return hashlib.sha256(f"{title}_{link}".encode("utf-8")).hexdigest()

def run_academic_notice():
    print("ğŸ“¢ í•œê²½êµ­ë¦½ëŒ€í•™êµ í•™ì‚¬ê³µì§€")
    print("=" * 30)

    base_url = "https://www.hknu.ac.kr/bbs/kor/70/artclList.do"
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Content-Type": "application/x-www-form-urlencoded"
    }

    # .envì—ì„œ DB ì—°ê²° ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
    conn = pymysql.connect(
        host=os.getenv("DB_HOST"),
        port=int(os.getenv("DB_PORT")),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        database=os.getenv("DB_NAME"),
        charset="utf8mb4"
    )
    cursor = conn.cursor()
    cursor.execute("SELECT hash FROM academic_notices")
    existing_hashes = set(row[0] for row in cursor.fetchall())

    page = 1
    empty_count = 0
    MAX_EMPTY = 3
    new_notices = []

    while True:
        print(f"ğŸ“„ í˜ì´ì§€ {page} ìˆ˜ì§‘ ì¤‘...")

        data = {
            "layout": "6b6f7240403536324040666e637431",  # í•™ì‚¬ê³µì§€ layout
            "page": str(page),
            "srchColumn": "",
            "srchWrd": "",
            "bbsClSeq": "",
            "bbsOpenWrdSeq": "",
            "rgsBgndeStr": "",
            "rgsEnddeStr": "",
            "isViewMine": "false"
        }

        try:
            res = requests.post(base_url, headers=headers, data=data, verify=False)
        except requests.exceptions.RequestException as e:
            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {e}")
            break

        if "board-table" not in res.text:
            print("ğŸ›‘ ê³µì§€ í…Œì´ë¸” ì—†ìŒ ë˜ëŠ” ë§ˆì§€ë§‰ í˜ì´ì§€ ë„ë‹¬")
            break

        soup = BeautifulSoup(res.text, "html.parser")
        rows = soup.select("table.board-table tbody tr")

        if not rows:
            break

        added = 0

        for row in rows:
            title_tag = row.select_one("td.td-subject a")
            date_tag = row.select_one("td.td-date")
            author_tag = row.select_one("td.td-write")

            if not title_tag or not date_tag:
                continue

            title = ' '.join(title_tag.text.split())
            href = "https://www.hknu.ac.kr" + title_tag['href']
            date = clean_date(date_tag.get_text(strip=True))
            author = author_tag.get_text(strip=True) if author_tag else "ì‘ì„±ì ì—†ìŒ"
            hash_value = generate_hash(title, href)

            if hash_value in existing_hashes:
                continue

            print(f"ğŸ“Œ {title} | {date} | {author}")
            new_notices.append((title, date, author, href, hash_value))
            added += 1

        if added == 0:
            empty_count += 1
        else:
            empty_count = 0

        if empty_count >= MAX_EMPTY:
            print(f"ğŸ›‘ {MAX_EMPTY}í˜ì´ì§€ ì—°ì†ìœ¼ë¡œ ìƒˆë¡œìš´ ê³µì§€ê°€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        page += 1

    if new_notices:
        sql = """
        INSERT INTO academic_notices (title, notice_date, author, link, hash)
        VALUES (%s, %s, %s, %s, %s)
        """
        cursor.executemany(sql, new_notices)
        conn.commit()
        print(f"âœ… {len(new_notices)}ê±´ì˜ ìƒˆ ê³µì§€ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("âœ… ìƒˆë¡œìš´ ê³µì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

    cursor.close()
    conn.close()